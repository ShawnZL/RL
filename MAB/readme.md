```python
self.estimates[k] += 1. / (self.counts[k] + 1) * (r - self.estimates[k])
```

这行代码更新了 `self.estimates[k]`，即关于被选择的臂 \( k \) 的期望奖励估计值。我们可以将其分解为几个部分来理解：

1. **`1. / (self.counts[k] + 1)`**
   - `self.counts[k]` 是一个计数器，记录臂 \( k \) 被选择的次数。
   - `self.counts[k] + 1` 是为了包括当前这次选择。
   - `1. / (self.counts[k] + 1)` 计算的是新观察到的奖励应该在总体估计中占的权重。随着选择次数的增加，这个权重会逐渐减小，这种方法类似于增量平均法。
   
2. **`(r - self.estimates[k])`**

   - `r` 是通过选择臂 \( k \) 后得到的实际奖励。
   - `self.estimates[k]` 是当前对臂 \( k \) 的奖励估计。
   - `(r - self.estimates[k])` 是一个误差项，表示实际奖励与当前估计之间的差距。

3. **`self.estimates[k] += ...`**

   - 这部分代码实现了对 `self.estimates[k]` 的更新。
   - `self.estimates[k] += 1. / (self.counts[k] + 1) * (r - self.estimates[k])` 使用步长 `1. / (self.counts[k] + 1)` 来调整 `self.estimates[k]`，使其更接近于新的观测值 `r`。
   - 该公式是增量形式的平均更新方法，逐步更新平均值，使其随着每次新观测值的到来而调整。

```
新的估计=旧的估计+学习率×(奖励−旧的估计)
```

这段代码在每次选择臂后更新对该臂的奖励估计值，使其逐渐收敛于真实的期望奖励。通过这种方式，算法可以在不需要存储所有历史奖励的情况下有效地跟踪奖励的变化。



```
self._a[k] += r
self._b[k] -= (1 - r)
```

在这段代码中，`self._a` 和 `self._b` 是用于跟踪每个臂的奖励结果的两个参数数组。它们用于更新 Beta 分布的参数，以反映每个臂在过去试验中的表现。这是 Thompson Sampling 算法的一部分，该算法用于解决多臂老虎机问题。

具体来说：

1. **`self._a[k] += r`**

   - `self._a` 是一个包含每个臂奖励为 1 的次数的数组。
   - `r` 是从 `self.bandit.step(k)` 中获得的奖励，它通常是二值的（0 或 1）。
   - 当 `r` 为 1 时，表示选择的臂 \( k \) 获得了奖励，因此 `self._a[k]` 增加 1。
   - 这相当于记录该臂出现奖励 1 的次数，用于更新 Beta 分布的第一个参数。

2. **`self._b[k] += (1 - r)`**

   - `self._b` 是一个包含每个臂奖励为 0 的次数的数组。
   - `1 - r` 计算的是未获得奖励的情况（因为 `r` 只会是 0 或 1）。
   - 当 `r` 为 0 时，表示选择的臂 \( k \) 没有获得奖励，因此 `self._b[k]` 增加 1。
   - 这相当于记录该臂出现奖励 0 的次数，用于更新 Beta 分布的第二个参数。

通过更新这两个参数，Thompson Sampling 算法可以在每次观察到新的奖励结果后，调整对每个臂的奖励分布的估计。这种调整使得算法能够在不确定性较大的情况下，更灵活地选择臂，从而在长时间内优化总奖励。





```
samples = np.random.beta(self._a, self._b)
```

`np.random.beta(self._a, self._b)` 是 NumPy 库中用于从 Beta 分布中生成随机样本的函数。Beta 分布是一种定义在 (0, 1) 区间上的连续概率分布，广泛用于贝叶斯统计和概率建模，特别是在处理概率和比例的问题时。

### 具体解释：
- **`np.random.beta(a, b)`**：这个函数从参数为 `a` 和 `b` 的 Beta 分布中生成随机样本。`a` 和 `b` 是 Beta 分布的两个形状参数，通常称为α（alpha）和β（beta）。
  
### Beta 分布的性质：
1. **形状参数**：
   - **`a`（α）**：控制曲线的左侧形状。如果 `a > 1`，曲线在左侧更陡峭。
   - **`b`（β）**：控制曲线的右侧形状。如果 `b > 1`，曲线在右侧更陡峭。
   
2. **用途**：
   - 当 `a = 1` 且 `b = 1` 时，Beta 分布是一个均匀分布。
   - 当 `a > 1` 和 `b > 1` 时，分布会在中间集中。
   - 当 `a < 1` 和 `b < 1` 时，分布会在两端集中。

3. **应用场景**：
   - **贝叶斯推断**：Beta 分布常用作二项分布的共轭先验分布，特别是在处理成功概率的估计时。
   - **A/B 测试**：在 A/B 测试中，Beta 分布用于估计不同版本的成功率。

### 使用示例：
假设 `self._a` 和 `self._b` 是在某个上下文中定义的变量，表示特定 Beta 分布的形状参数，`np.random.beta(self._a, self._b)` 将根据这些参数生成一个在 0 到 1 之间的随机样本。

这个生成的样本可以用于模拟、蒙特卡洛方法或其他需要从 Beta 分布中取样的统计分析任务。



# todo

ucb Thompson

## UCB

**证明根据这件事发生的概率小于等于1来证明**

选择 \(\delta\) 在 \([1, \infty)\) 区间是为了确保概率不等式 \(p \le \tilde{p} + \delta\) 恒成立。以下是为什么可以这样选择的原因：

1. **理论保证**：
   - 对于任何真实概率 \(p\)，只要 \(\delta\) 足够大，\(\tilde{p} + \delta\) 就会超过 \(p\)，因此不等式始终成立。

2. **偏差范围**：
   - 较大的 \(\delta\) 意味着允许更大的偏差范围，这在理论上保证了不等式的成立。

3. **单调性**：
   - 因为 \(1 - e^{-2n\delta^2}\) 是关于 \(\delta\) 单调递增的，所以随着 \(\delta\) 增大，表达式更接近 1，偏差可能性减少。

然而，实际应用中通常选择更小的 \(\delta\)，如 \(\delta = \sqrt{\frac{\ln N}{2n}}\)，以提供更紧密的界限和更有意义的结果。选择 \([1, \infty)\) 区间更多是理论上的保证，而非实际应用中的最佳选择。



## Thompson Sampling

MAB 中还有一种经典算法——**汤普森采样**（Thompson sampling），先假设拉动每根拉杆的奖励服从一个特定的概率分布，然后根据拉动每根拉杆的期望奖励来进行选择。但是由于计算所有拉杆的期望奖励的代价比较高，汤普森采样算法使用采样的方式，即根据当前每个动作 a 的奖励概率分布进行一轮采样，得到一组各根拉杆的奖励样本，再选择样本中奖励最大的动作。可以看出，汤普森采样是一种计算所有拉杆的最高奖励概率的蒙特卡洛采样方法。

了解了汤普森采样算法的基本思路后，我们需要解决另一个问题：怎样得到当前每个动作 a 的奖励概率分布并且在过程中进行更新？在实际情况中，我们通常用 Beta 分布对当前每个动作的奖励概率分布进行建模。具体来说，若某拉杆被选择了 k 次，其中 m1 次奖励为 1，m2 次奖励为 0，则该拉杆的奖励服从参数为 (m1, m2) 的 Beta 分布。

![](https://img2018.cnblogs.com/blog/1102791/201907/1102791-20190721104211268-1337262284.png)

从Beta分布的概率密度函数的图形我们可以看出，Beta分布有很多种形状，但都是在0-1区间内，因此Beta分布可以描述各种0-1区间内的形状（事件）。因此，它特别适合为某件事发生或者成功的概率建模。同时，当α=1，β=1的时候，它就是一个均匀分布。

**Beta分布主要有 α和 β两个参数，这两个参数决定了分布的形状，从上图及其均值和方差的公式可以看出：**

1）α/(α+β)也就是均值，其越大，概率密度分布的中心位置越靠近1，依据此概率分布产生的随机数也多说都靠近1，反之则都靠近0。

2）α+β越大，则分布越窄，也就是集中度越高，这样产生的随机数更接近中心位置，从方差公式上也能看出来。